{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c38e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload  \n",
    "%autoreload 2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b44b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "from dataset import TrainDataset, extract_data\n",
    "from itertools import product\n",
    "from model import HybridLSTMGRU\n",
    "import evaluation as eval\n",
    "\n",
    "from train import train_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddda2b9",
   "metadata": {},
   "source": [
    "# Chômage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc799a",
   "metadata": {},
   "source": [
    "Dataset extrait chômage :\n",
    "\n",
    "- Date : 1983-01 à 2024-12\n",
    "- Zone : France, USA, United Kingdom, Italie\n",
    "- Mesure: Taux de chomage mensuel\n",
    "- Unité: Pourcentage de la population active \n",
    "- Ajustemenet : corrigé des variations saisonieres, et des effets de calendrier (data_ocde_corr)\n",
    "- Sexe: Tout \n",
    "- Age: 15 ans et plus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadddd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Datasets/data_ocde_cor.csv\", usecols=[\"TIME_PERIOD\",'REF_AREA', \"OBS_VALUE\"])\n",
    "\n",
    "pays_avaliable = dataset[\"REF_AREA\"].unique()\n",
    "pays = \"FRA\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca53ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_FRA = dataset[dataset[\"REF_AREA\"] == pays]\n",
    "dataset_FRA.loc[:, 'TIME_PERIOD'] = pd.to_datetime(dataset_FRA[\"TIME_PERIOD\"])\n",
    "dataset_FRA = dataset_FRA.sort_values(by='TIME_PERIOD')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dataset_FRA['TIME_PERIOD'], dataset_FRA['OBS_VALUE'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Valeur')\n",
    "plt.title('Évolution des valeurs dans le temps')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Formatage auto de l'axe x\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(40))  # max 10 dates visibles\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c3f1e1",
   "metadata": {},
   "source": [
    "# Séparation Entrainement/Validation/Test pour les données de chômage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460a0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "pays = \"ITA\"\n",
    "type = 'chomage'\n",
    "ville = None\n",
    "saison = None\n",
    "\n",
    "# Parametres tester\n",
    "lr_list = [0.01, 0.001, 0.0001]\n",
    "batch_list = [16, 32, 64]\n",
    "seq_len_list = [3,6,9,12,15,18,21,24]\n",
    "\n",
    "best_results_all = []\n",
    "\n",
    "for lr, seq_len, batch_size in product(lr_list, seq_len_list, batch_list):\n",
    "        print(f\"Combinaison testée: lr={lr}, seq_len={seq_len}, batch_size={batch_size}\")\n",
    "        \n",
    "        config = {\"epochs\": 1500,\n",
    "                \"batch_size\": batch_size,\n",
    "                \"lr\":lr,\n",
    "                \"seq_len\": seq_len,\n",
    "                \"shift\": 1,\n",
    "                \"scaler\": \"MinMaxScaler\",\n",
    "                \"prop\": [0.7, 0.15, 0.15],\n",
    "                \"type\": type,\n",
    "                \"pays\": pays,\n",
    "                \"ville\": ville,\n",
    "                \"saison\": None,\n",
    "                \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                \"seed\": 42,\n",
    "        }\n",
    "        _, best = train_config(dataset, config)\n",
    "        print(f'Meilleure RMSE de validation est de {best[\"val_rmse\"]} pour {best[\"epoch\"]} epochs')  \n",
    "        best_results_all.append(best)\n",
    "        \n",
    "results_df = pd.DataFrame(best_results_all)\n",
    "results_df.to_csv(f'Best_parameters/{type}_{pays}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1c1101",
   "metadata": {},
   "source": [
    "# Températures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9ec54b",
   "metadata": {},
   "source": [
    "#### Comparer les résultats entre les modèles testés et parler du meilleur modèle\n",
    "\n",
    "#### Meilleur modèle bien meilleur que le naif dans ce cas en raison des changements drastiques ce qui n'est pas le cas pour le chomage pas autant dépendant du mois\n",
    "\n",
    "#### Comparer meilleur modèle température vs chômage. Est-ce le même? Est-ce qu'il performe mieux sur un type de données?\n",
    "\n",
    "#### Potentiellement voir si le meilleur modèle change pour différents pays et si meilleures performances\n",
    "\n",
    "#### Voir si même modèle optimal pour désaisonnalisé vs pas désaisonnalisé et quel performe mieux\n",
    "\n",
    "#### Conclusion on peut voir que le type de données affecte les performances de ce modèle qui performe mieux sur les données températures que sur les données de chômage, puisque naif meilleur pour chômage mais pas le cas pour température. Cela peut être dû au fait que le chômage dépend plus de sa dernière valeur tandis que les températures changent plus drastiquement on peut penser par exemple au mois de décembre vs janvier peut-être. Il est donc pas bon de garder valeur de décembre comme prédiction pour janvier tandis que oui pour le chômage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d241563",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_temp = pd.read_csv(\"Datasets/city_temperatures.csv\", usecols=[\"Year\", 'Month', 'Day', 'Country', 'City', 'AvgTemperature'])\n",
    "\n",
    "# Puisqu'il y a des valeurs de -99 Farenheit pour certaines journnées, on peut assumer que celles-ci sont le résultat de valeurs manquantes\n",
    "# On peut donc enlever ces valeurs de l'ensemble de données\n",
    "dataset_temp = dataset_temp[dataset_temp['AvgTemperature'] > 0].reset_index(drop=True)\n",
    "\n",
    "# Par la suite, on transforme les données pour avoir une moyenne des températures à chaque mois plutôt qu'à chaque année\n",
    "dataset_temp_mensuel = dataset_temp.groupby(['Country', 'City', 'Year', 'Month'])['AvgTemperature'].mean().reset_index()\n",
    "\n",
    "dataset_temp_mensuel['Time Period'] = dataset_temp_mensuel['Year'].astype(str) + '-' + dataset_temp_mensuel['Month'].astype(str)\n",
    "dataset_temp_mensuel.loc[:, 'Time Period'] = pd.to_datetime(dataset_temp_mensuel['Time Period']).dt.date\n",
    "\n",
    "\n",
    "# On fait le modèle pour les températures moyennes par mois à Paris en France\n",
    "pays = 'France'\n",
    "ville = 'Paris'\n",
    "\n",
    "dataset_temp_mensuel_Paris = dataset_temp_mensuel[(dataset_temp_mensuel[\"City\"] == ville) & (dataset_temp_mensuel[\"Country\"] == pays)].reset_index(drop=True)\n",
    "dataset_temp_mensuel_Paris = dataset_temp_mensuel_Paris.sort_values(by='Time Period')\n",
    "\n",
    "# On visualise la série chronologique\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dataset_temp_mensuel_Paris['Time Period'], dataset_temp_mensuel_Paris['AvgTemperature'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Température Moyenne')\n",
    "plt.title('Évolution des températures moyennes à Paris au fil des mois de janvier 1995 à mai 2020')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Formatage auto de l'axe x\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(40))  # max 10 dates visibles\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbe1be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comme les données du chômage étaient désaisonnalisées, on effectue le même traitement pour ces données qui ont clairement une saisonnalité\n",
    "# sur les 12 mois de l'année\n",
    "\n",
    "stl = STL(dataset_temp_mensuel_Paris['AvgTemperature'], period = 12, robust = True)\n",
    "res = stl.fit()\n",
    "\n",
    "dataset_temp_mensuel_Paris['Saisonnalité'] = res.seasonal\n",
    "dataset_temp_mensuel_Paris['AvgTemperature Adjusted'] = dataset_temp_mensuel_Paris['AvgTemperature'] - dataset_temp_mensuel_Paris['Saisonnalité']\n",
    "\n",
    "# res.plot()\n",
    "# plt.show()\n",
    "\n",
    "# On visualise la série chronologique désaisonnalisée\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dataset_temp_mensuel_Paris['Time Period'], dataset_temp_mensuel_Paris['AvgTemperature Adjusted'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Température Moyenne Ajustée')\n",
    "plt.title('Évolution des températures moyennes ajustées à Paris au fil des mois de janvier 1995 à mai 2020')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Formatage auto de l'axe x\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(40))  # max 10 dates visibles\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2055336a",
   "metadata": {},
   "source": [
    "# On trouve les meilleurs hyper-paramètres pour lr, seq_len et batch size pour les données sur la température désaisonnalisée pour les données de Paris, France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f01fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres fixes du modèle \n",
    "pays = 'Italy'\n",
    "ville = 'Rome'\n",
    "type = 'temperature'\n",
    "saison = True\n",
    "\n",
    "# Parametres tester\n",
    "lr_list = [0.01, 0.001, 0.0001]\n",
    "batch_list = [16, 32, 64]\n",
    "seq_len_list = [3,6,9,12,15,18,21,24]\n",
    "\n",
    "best_results_all = []\n",
    "\n",
    "for lr, seq_len, batch_size in product(lr_list, seq_len_list, batch_list):\n",
    "        print(f\"Combinaison testée: lr={lr}, seq_len={seq_len}, batch_size={batch_size}\")\n",
    "        \n",
    "        config = {\"epochs\": 1500,\n",
    "                \"batch_size\": batch_size,\n",
    "                \"lr\":lr,\n",
    "                \"seq_len\": seq_len,\n",
    "                \"shift\": 1,\n",
    "                \"scaler\": \"MinMaxScaler\",\n",
    "                \"prop\": [0.7, 0.15, 0.15],\n",
    "                \"type\": type,\n",
    "                \"pays\": pays,\n",
    "                \"ville\": ville,\n",
    "                \"saison\": saison,\n",
    "                \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                \"seed\": 42,\n",
    "        }\n",
    "        _, best = train_config(dataset_temp, config)\n",
    "        print(f'Meilleure RMSE de validation est de {best[\"val_rmse\"]} pour {best[\"epoch\"]} epochs')  \n",
    "        best_results_all.append(best)\n",
    "        \n",
    "results_df = pd.DataFrame(best_results_all)\n",
    "results_df.to_csv(f'Best_parameters/{type}_{pays}_{ville}_{\"with_season\" if saison else \"without_season\"}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c1300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Best_parameters/temperature_France_Paris_with_season.csv\", \"r\") as f:\n",
    "    results_df = pd.read_csv(f)\n",
    "\n",
    "# On regarde quelle combinaison s'hyper-paramètres à donner la meilleure valeur de RMSE test\n",
    "best_row = results_df.loc[results_df['val_rmse'].idxmin()]\n",
    "best_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be86411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On réentraine donc le modèle avec le même seed (42), puis on obtient le graphique des prédictions et des valeurs réelles\n",
    "# On compare également les performances du modèle contre les performances d'un modèle naif\n",
    "\n",
    "# Paramètres fixes du modèle \n",
    "pays = 'France'\n",
    "ville = 'Paris'\n",
    "type = 'temperature'\n",
    "saison = True\n",
    "\n",
    "# Paramètres optimaux\n",
    "EPOCHS_opt = 1250\n",
    "lr_opt = 0.0001\n",
    "seq_len_opt = 21\n",
    "batch_size_opt = 16\n",
    "\n",
    "config = {\"epochs\": EPOCHS_opt,\n",
    "                \"batch_size\": batch_size_opt,\n",
    "                \"lr\":lr_opt,\n",
    "                \"seq_len\": seq_len_opt,\n",
    "                \"shift\": 1,\n",
    "                \"scaler\": \"MinMaxScaler\",\n",
    "                \"prop\": [0.7, 0.15, 0.15],\n",
    "                \"type\": type,\n",
    "                \"pays\": pays,\n",
    "                \"ville\": ville,\n",
    "                \"saison\": saison,\n",
    "                \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                \"seed\": 42,\n",
    "        }\n",
    "model_temp, best = train_config(dataset_temp, config)\n",
    "\n",
    "\n",
    "if config[\"scaler\"] == \"MinMaxScaler\":\n",
    "        scaler = MinMaxScaler()\n",
    "else:\n",
    "        scaler = None\n",
    "        \n",
    "train_data, val_data, test_data = extract_data(\n",
    "        dataset_temp,\n",
    "        config[\"pays\"],\n",
    "        config[\"prop\"],\n",
    "        config[\"type\"],\n",
    "        saison=config[\"saison\"],\n",
    "        ville=config[\"ville\"],\n",
    "        scaler=scaler,\n",
    "    )\n",
    "# On évalue le modèle sur les données test\n",
    "test_rmse_temp, test_mae_temp, test_mape_temp = eval.evaluate(model_temp, test_data, val_data, seq_len_opt, scaler)\n",
    "naive_rmse_temp, naive_mae_temp, naive_mape_temp = eval.evaluate_naive(test_data, val_data, seq_len_opt, scaler)\n",
    "\n",
    "print(f\"Test - RMSE: {test_rmse_temp:.4f},  MAE: {test_mae_temp:.4f}, MAPE: {test_mape_temp:.4f}\")\n",
    "print(f\"Naive - RMSE: {naive_rmse_temp:.4f},  MAE: {naive_mae_temp:.4f}, MAPE: {naive_mape_temp:.4f}\")\n",
    "\n",
    "eval.plot_prediction(model_temp, test_data, val_data, seq_len_opt, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874fd988",
   "metadata": {},
   "source": [
    "# On trouve les meilleurs hyper-paramètres pour lr, seq_len et batch size pour les données sur la température qui ne sont pas désaisonnalisées pour les données de Paris, France"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e36c91",
   "metadata": {},
   "source": [
    "# On trouve les meilleurs hyper-paramètres pour lr, seq_len et batch size pour les données sur la température désaisonnalisées pour les données de Rome, Italie"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf_8225_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
